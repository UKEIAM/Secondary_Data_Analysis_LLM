{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from vllm import LLM, SamplingParams\n",
    "from datetime import datetime\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Testdata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Reading csv-Files\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m DF \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTestdata.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m   \n\u001b[1;32m      4\u001b[0m df_0 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(DF)\n\u001b[1;32m      6\u001b[0m df_0\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Testdata.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reading csv-Files\n",
    "\n",
    "DF = pd.read_csv('Testdata.csv', sep=';')   \n",
    "df_0 = pd.DataFrame(DF)\n",
    "\n",
    "df_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Geb_3\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Update original variables\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m df_0 \u001b[38;5;241m=\u001b[39m process_dataframe(\u001b[43mdf_0\u001b[49m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Delete unnecessary rows\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m df_0[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_0' is not defined"
     ]
    }
   ],
   "source": [
    "# Define timeformats\n",
    "timeformat = \"%b %d %Y  %I:%M%p\"\n",
    "birthdayformat = \"%m/%Y\"\n",
    "\n",
    "# Define process to add Age-column\n",
    "def process_dataframe(df):\n",
    "    df['CollectedDT'] = pd.to_datetime(df['CollectedDT'], format=timeformat, errors='coerce')\n",
    "    \n",
    "    Geb_0 = df[df['Finding'] == \"Geburtsdatum\"]\n",
    "    Geb_1 = Geb_0[['MPINumber', 'Value']].copy()\n",
    "    Geb_1 = Geb_1.drop_duplicates()\n",
    "    Geb_1 = Geb_1.rename(columns={\"Value\": \"Birthday\"})\n",
    "    \n",
    "    Geb_2 = Geb_1.loc[:, ['MPINumber', 'Birthday']].copy()\n",
    "    \n",
    "    Geb_2['Birthday'] = pd.to_datetime(Geb_2['Birthday'], format=birthdayformat, errors='coerce')\n",
    "    # print(Geb_2.head())\n",
    "    Geb_3 = pd.merge(df, Geb_2, how=\"left\", on=\"MPINumber\")\n",
    "    \n",
    "    Geb_3['Age'] = ((Geb_3['CollectedDT'] - Geb_3['Birthday']).dt.days) // 365.25\n",
    "    # Geb_3['Age'] = Geb_3['Age'].astype(\"string\")\n",
    "    # Geb_3['Age'] = Geb_3['Age'].str.replace('.0', '', regex=False)\n",
    "    \n",
    "    # print(Geb_3.head())\n",
    "    return Geb_3\n",
    "\n",
    "\n",
    "# Update original variables\n",
    "df_0 = process_dataframe(df_0)\n",
    "\n",
    "# Delete unnecessary rows\n",
    "del df_0['Unnamed: 0']\n",
    "del df_0['FindingName']\n",
    "del df_0['FindingDataType']\n",
    "del df_0['PatientAccountID']\n",
    "del df_0['AssessmentID']\n",
    "del df_0['Birthday']\n",
    "\n",
    "# Avoid Value Errors due to Na / NaN values\n",
    "df_0 = df_0.fillna(0)\n",
    "\n",
    "\n",
    "print(df_0.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m ICD_10_Code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH36\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Filter the data\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m diagnosed_patients \u001b[38;5;241m=\u001b[39m \u001b[43mdf_0\u001b[49m[(df_0[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiagnose\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m (df_0[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(ICD_10_Code))][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMPINumber\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Create new data frame containing only the relevant patients\u001b[39;00m\n\u001b[1;32m     10\u001b[0m df_P \u001b[38;5;241m=\u001b[39m df_0[df_0[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMPINumber\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(diagnosed_patients)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_0' is not defined"
     ]
    }
   ],
   "source": [
    "# Filter the dataframe for patients with relevant diagnosis/ ICD10-Code\n",
    "\n",
    "# Choose reelvant diagnosis\n",
    "ICD_10_Code = 'H36'\n",
    "\n",
    "# Filter the data\n",
    "diagnosed_patients = df_0[(df_0['Finding'] == 'Diagnose') & (df_0['Value'].str.contains(ICD_10_Code))]['MPINumber'].unique()\n",
    "\n",
    "# Create new data frame containing only the relevant patients\n",
    "df_P = df_0[df_0['MPINumber'].isin(diagnosed_patients)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose your LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-04 13:49:43 config.py:350] This model supports multiple tasks: {'generate', 'embedding'}. Defaulting to 'generate'.\n",
      "WARNING 12-04 13:49:43 config.py:428] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "INFO 12-04 13:49:43 llm_engine.py:249] Initializing an LLM engine (v0.6.4.post1) with config: model='TheBloke/Mistral-7B-Instruct-v0.2-AWQ', speculative_config=None, tokenizer='TheBloke/Mistral-7B-Instruct-v0.2-AWQ', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=awq, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=TheBloke/Mistral-7B-Instruct-v0.2-AWQ, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)\n",
      "INFO 12-04 13:49:45 selector.py:261] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 12-04 13:49:45 selector.py:144] Using XFormers backend.\n",
      "INFO 12-04 13:49:46 model_runner.py:1072] Starting to load model TheBloke/Mistral-7B-Instruct-v0.2-AWQ...\n",
      "INFO 12-04 13:49:46 weight_utils.py:243] Using model weights format ['*.safetensors']\n",
      "INFO 12-04 13:51:27 weight_utils.py:288] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.17it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.17it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-04 13:51:28 model_runner.py:1077] Loading model weights took 3.8814 GB\n",
      "INFO 12-04 13:51:30 worker.py:232] Memory profiling results: total_gpu_memory=15.74GiB initial_memory_usage=5.62GiB peak_torch_memory=4.73GiB memory_usage_post_profile=5.67GiB non_torch_memory=1.79GiB kv_cache_size=7.65GiB gpu_memory_utilization=0.90\n",
      "INFO 12-04 13:51:30 gpu_executor.py:113] # GPU blocks: 3915, # CPU blocks: 2048\n",
      "INFO 12-04 13:51:30 gpu_executor.py:117] Maximum concurrency for 8192 tokens per request: 7.65x\n",
      "INFO 12-04 13:51:33 model_runner.py:1400] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 12-04 13:51:33 model_runner.py:1404] If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 12-04 13:51:59 model_runner.py:1518] Graph capturing finished in 26 secs, took 1.39 GiB\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(\"TheBloke/Mistral-7B-Instruct-v0.2-AWQ\", max_model_len=32768/4, dtype=\"auto\", quantization=\"awq\")\n",
    "\n",
    "# llm = LLM(\"casperhansen/llama-3-8b-instruct-awq\", max_model_len=32768/4, dtype=\"auto\", quantization=\"awq\")\n",
    "\n",
    "# llm = LLM(\"TheBloke/CodeLlama-7B-Instruct-AWQ\", max_model_len=32768/4, dtype=\"half\", quantization=\"awq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tokenizer for chat template\n",
    "\n",
    "\n",
    "# Use this for Mistral and Llama3\n",
    "\n",
    "tokenizer = llm.get_tokenizer()\n",
    "\n",
    "\n",
    "# Use this for CodeLlama\n",
    "\n",
    "#from transformers import AutoTokenizer\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"codellama/CodeLlama-7b-Instruct-hf\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_B_1 = \"How many patients are there?\"\n",
    "Question_B_2 = \"Plot the gender distribution in a pie chart, include percentages.\"\n",
    "Question_B_3 = \"Plot a bar graph for the number of patients per age. Remember to only count each patient/MPINumber once.\"\n",
    "Question_B_4 = \"Count the number of patients for each unique diagnosis. Plot the 5 most common diagnoses except B50, B51, B52, B53, B54 and A97 in a bar graph.\"\n",
    "Question_B_5 = \"Count the number of patients that got diagnosed with both (B50, B51, B52, B53 or B54) and also A97.\"\n",
    "Question_B_6 = \"Plot the gender distribution of all patients that got diagnosed with B50, B51, B52, B53, B54 in a pie chart, include percentages. Then, repeat for all patients that got diagnosed with A97\"\n",
    "Question_B_7 = \"Plot the age of all patients that got diagnosed with B50, B51, B52, B53, B54 in a bar chart. Then repeat for all patients that got diagnosed with A97\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_H_1 = \"How many patients are there?\"\n",
    "Question_H_2 = \"Plot the gender distribution in a pie chart, include percentages.\"\n",
    "Question_H_3 = \"Plot a bar graph for the number of patients per age. Remember to only count each patient/MPINumber once.\"\n",
    "Question_H_4 = \"Count the number of patients for each unique diagnosis. Plot the 5 most common diagnoses except H36 in a bar graph. \"\n",
    "Question_H_5 = \"How many HBA1CNV lab results does each patient have? Plot the number of patients that had each number of lab results in a bar graph.\"\n",
    "Question_H_6 = \"Count HBA1CNV lab results for each patient. Plot the measurement values for patients with exactly 5 HBA1CNV lab results in boxplots. Then plot dotted horizontal lines for the values 4.5, 5.7., 6.5. and 7.5.\"\n",
    "Question_H_7 = \"Count HBA1CNV lab results for each patient. Plot the measurement values for patients with exactly 5 HBA1CNV lab results over time. Then plot dotted horizontal lines for the values 4.5, 5.7., 6.5. and 7.5.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_H_1_German = \"Wie viele Patienten gibt es?\"\n",
    "Question_H_2_German = \"Zeichne die Geschlechterverteilung in ein Tortendiagramm, beziehe Prozentzahlen mit ein.\"\n",
    "Question_H_3_German = \"Zeichne ein Balkendiagramm for die Anzahl an Patienten pro Alter. Denke daran jeden Patienten/MPINumber nur einmal zu zählen.\"\n",
    "Question_H_4_German = \"Zähle die Anzahl der Patienten für jede einzigartige Diagnose. Zeichne die 5 häufigsten Diagnoses ausser H36 in einem Balkendiagramm.\"\n",
    "Question_H_5_German = \"Wie viele HBA1CNV Laborwerte hat jeder Patient? Zeichne die Anzahl an Patienten die die jeweilige Anzahl an Laborwerte hatten in einem Balkendiagramm.\"\n",
    "Question_H_6_German = \"Zähle die HBA1CNV Laborwerte für jeden Patient. Zeichne die Messwerte für Patienten mit exakt 5 HBA1CNV Laborwerten in einem Balkendiagramm. Zeichne dann gepunktete horizontale Linien für die Werte 4.5, 5.7, 6.5 und 7.5.\"\n",
    "Question_H_7_German = \"Zähle die HBA1CNV Laborwerte für jeden Patient. Zeichne die Messwerte für Patienten mit exakt 5 HBA1CNV Laborwerten über die Zeit. Zeichne dann gepunktete horizontale Linien für die Werte 4.5, 5.7, 6.5 und 7.5.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrasing - Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_H_1_Keyword = \"Number of patients.\"\n",
    "Question_H_2_Keyword = \"Gender distribution in pie graph.\"\n",
    "Question_H_3_Keyword = \"Age distribution in bar graph.\"\n",
    "Question_H_4_Keyword = \"Five most common diagnoses besides H36 in bar graph\"\n",
    "Question_H_5_Keyword = \"HBA1CNV lab results per patient\"\n",
    "Question_H_6_Keyword = \"HBA1CNV values for patients with 5 HBA1CNV lab results in boxplot.\"\n",
    "Question_H_7_Keyword = \"HBA1CNV values for patients with 5 HBA1CNV values over time.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Phrasing - Short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_H_1_Short = \"How many different patients are there?\"\n",
    "Question_H_2_Short = \"Plot a gender pie chart with percentages.\"\n",
    "Question_H_3_Short = \"Plot an age bar graph.\"\n",
    "Question_H_4_Short = \"Plot a boxplot for the five side diagnoses besides H36.\"\n",
    "Question_H_5_Short = \"Plot how many patients had how many HBA1CNV lab results.\"\n",
    "Question_H_6_Short = \"Plot the HBA1CNV values for patients with 5 HBA1CNV lab results in a boxplot.\"\n",
    "Question_H_7_Short = \"Plot the HBA1CNV values for patients with 5 HBA1CNV lab results over time.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrasing - Data science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_H_1_Data_science = \"How many different patients does the dataset contain?\"\n",
    "Question_H_2_Data_science = \"Plot the distribution of gender for all patients in a pie chart. Include percentages in the pie chart.\"\n",
    "Question_H_3_Data_science = \"Plot the age of the patients in a bar graph, one bar for each age with the number of patients with that age as the height.\"\n",
    "Question_H_4_Data_science = \"How often does each diagnosis occur in the dataset? Plot the number of occurences for the five most common diagnoses in a bar graph while excluding the diagnosis H36 \"\n",
    "Question_H_5_Data_science = \"How often did each patient get a HBA1CNV measurement? Plot the number of measuremnts in a bar graph, with the number of patients that had that exact number of measurements as the height.\"\n",
    "Question_H_6_Data_science = \"How often did each patient get a HBA1CNV measurement? Plot the measurement values for every patient with exactly 5 lab results in seperate boxplots. Then add dotted horizontal lines at the heights 4.5, 5.7, 6.5 and 7.5 to the graph.\"\n",
    "Question_H_7_Data_science = \"How often did each patient get a HBA1CNV measurement? Plot the measurement values for every patient with exactly 5 lab results as a line graph over time. Then add dotted horizontal lines at the heights 4.5, 5.7, 6.5 and 7.5 to the graph.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrasing - Medical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_H_1_Medical = \"On how many patients does data exist?\"\n",
    "Question_H_2_Medical = \"Show me the ratio between male and female patients in a round graph, including percentages.\"\n",
    "Question_H_3_Medical = \"Show me the age of all patients in a graph.\"\n",
    "Question_H_4_Medical = \"What were the five most common side diagnoses besides Retinopathia diabetica? Show me their number in a graph.\"\n",
    "Question_H_5_Medical = \"How often did each patient get their blood sugar measured in the lab? Show me how many patients got how many blood sugar lab results.\"\n",
    "Question_H_6_Medical = \"Show me the blood sugar values for patients that got exactly five blood sugar lab results.\"\n",
    "Question_H_7_Medical = \"Show me how the blood sugar values change over time for patients that got exactly five blood sugar lab results.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_template_zero(df: pd.DataFrame, query: str, tokenizer):\n",
    "    llm_chat = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "Your job is to always write python code for the given dataframe `df` using pandas, numpy and matplot library.\n",
    "Never execute the code.\n",
    "            \n",
    "The first twenty rows of the dataframe are:\n",
    "{df.head(20)}\n",
    "            \n",
    "The columns of the dataframe are:\n",
    "{df.columns}\n",
    "\n",
    "Every patient has a unique `MPINumber`.         \n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\"\n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(llm_chat, add_generation_prompt=True, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_template_zero_chain(df: pd.DataFrame, query: str, tokenizer):\n",
    "    llm_chat = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "Always think step by step.\n",
    "Your job is to always write python code for the given dataframe `df` using pandas, numpy and matplot library.\n",
    "Never execute the code.\n",
    "            \n",
    "The first twenty rows of the dataframe are:\n",
    "{df.head(20)}\n",
    "            \n",
    "The columns of the dataframe are:\n",
    "{df.columns}\n",
    "\n",
    "Every patient has a unique `MPINumber`.         \n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\"\n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(llm_chat, add_generation_prompt=True, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_template_one(df: pd.DataFrame, query: str, tokenizer):\n",
    "    llm_chat = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "Your job is to always write python code for the given dataframe `df` using pandas, numpy and matplot library.\n",
    "Never execute the code.\n",
    "            \n",
    "The first twenty rows of the dataframe are:\n",
    "{df.head(20)}\n",
    "            \n",
    "The columns of the dataframe are:\n",
    "{df.columns}\n",
    "\n",
    "Every patient has a unique `MPINumber`.          \n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\"\n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "Count the number of patients.\n",
    "Then, count the number of diagnoses. \n",
    "Then, count the number of patients with a X00 diagnosis.\n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\"\n",
    "```\n",
    "# Number of patients\n",
    "print(len(df['MPINumber'].unique()))\n",
    "``` \n",
    "\n",
    "```\n",
    "# Count diagnoses\n",
    "df_diagnoses = df[df['Finding'] == 'Diagnose']\n",
    "print(len(df_diagnoses))\n",
    "```\n",
    "\n",
    "```\n",
    "# Count X00 patients\n",
    "df_X00 = df[(df['Finding'].str.contains('Diagnose')) & (df['Value'].str.contains('X00'))]['MPINumber'].unique()\n",
    "print(len(df_X00))\n",
    "```            \n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(llm_chat, add_generation_prompt=True, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_template_one_chain(df: pd.DataFrame, query: str, tokenizer):\n",
    "    llm_chat = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "Always think step by step.            \n",
    "Your job is to always write python code for the given dataframe `df` using pandas, numpy and matplot library.\n",
    "Never execute the code.\n",
    "            \n",
    "The first twenty rows of the dataframe are:\n",
    "{df.head(20)}\n",
    "            \n",
    "The columns of the dataframe are:\n",
    "{df.columns}\n",
    "\n",
    "Every patient has a unique `MPINumber`.          \n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\"\n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "Count the number of patients.\n",
    "Then, count the number of diagnoses. \n",
    "Then, count the number of patients with a X00 diagnosis.\n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\"\n",
    "```\n",
    "# Number of patients\n",
    "print(len(df['MPINumber'].unique()))\n",
    "``` \n",
    "\n",
    "```\n",
    "# Count diagnoses\n",
    "df_diagnoses = df[df['Finding'] == 'Diagnose']\n",
    "print(len(df_diagnoses))\n",
    "```\n",
    "\n",
    "```\n",
    "# Count X00 patients\n",
    "df_X00 = df[(df['Finding'].str.contains('Diagnose')) & (df['Value'].str.contains('X00'))]['MPINumber'].unique()\n",
    "print(len(df_X00))\n",
    "```            \n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(llm_chat, add_generation_prompt=True, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_template_few(df: pd.DataFrame, query: str, tokenizer):\n",
    "    llm_chat = [\n",
    "                {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "Your job is to always write python code for the given dataframe `df` using pandas, numpy and matplot library.\n",
    "Never execute the code.\n",
    "            \n",
    "The first twenty rows of the dataframe are:\n",
    "{df.head(20)}\n",
    "            \n",
    "The columns of the dataframe are:\n",
    "{df.columns}\n",
    "\n",
    "Every patient has a unique `MPINumber`.          \n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\"\n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "Count the number of patients.\n",
    "Then, count the number of diagnoses. \n",
    "Then, count the number of patients with a X00 diagnosis.\n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\"\n",
    "```\n",
    "# Number of patients\n",
    "print(len(df['MPINumber'].unique()))\n",
    "``` \n",
    "\n",
    "```\n",
    "# Count diagnoses\n",
    "df_diagnoses = df[df['Finding'] == 'Diagnose']\n",
    "print(len(df_diagnoses))\n",
    "```\n",
    "\n",
    "```\n",
    "# Count X00 patients\n",
    "df_X00 = df[(df['Finding'].str.contains('Diagnose')) & (df['Value'].str.contains('X00'))]['MPINumber'].unique()\n",
    "print(len(df_X00))\n",
    "```            \n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "Plot patients with a Y123 lab result against patients without one in a pie chart. Include percentages and a legend.       \n",
    "\"\"\"            \n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\" \n",
    "```\n",
    "# Filter dataframe for patients with and without 'Y123' lab result\n",
    "df_Y123 = df[(df['Source'].str.contains('Labor')) & (df['Finding'].str.contains('Y123'))]['MPINumber'].unique()\n",
    "df_no_Y123 = df[~df['MPINumber'].isin(df_Y123)]\n",
    "\n",
    "# Count number of patients in each group\n",
    "num_Y123 = len(df_Y123)\n",
    "num_no_Y123 = len(df_no_Y123)\n",
    "\n",
    "# Plot pie chart\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = ['Patients with Y123 lab result', 'Patients without Y123 lab result']\n",
    "sizes = [num_Y123, num_no_Y123]\n",
    "\n",
    "plt.pie(sizes, labels=labels, startangle=90, autopct='%1.1f%%')\n",
    "plt.axis('equal')\n",
    "plt.title('Patients with and without Y123 lab result')\n",
    "plt.legend(title='Patients', loc='upper right')\n",
    "plt.show()\n",
    "``` \n",
    "\"\"\"\n",
    "        },\n",
    "                \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "Which 5 patients had the most Y123 lab result? Plot the values for the patient with the most results in a boxplot.     \n",
    "\"\"\"            \n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\"\n",
    "```\n",
    "# Filter for patients with y123 lab result             \n",
    "df_Y123 = df[(df['Source'].str.contains('Labor')) & (df['Finding'].str.contains('Y123'))]\n",
    "\n",
    "# Group by 'MPINumber' and count the occurrences of 'Y123' lab results\n",
    "df_Y123_counts = df_Y123.groupby('MPINumber').size().reset_index(name='Count')\n",
    "\n",
    "# Sort by count in descending order and select the top 5 patients\n",
    "top_5_Y123 = df_Y123_counts.sort_values(by='Count', ascending=False).head(5)\n",
    "\n",
    "# Display the top 5 patients with the most Y123 lab results\n",
    "print(\"Top 5 patients with the most Y123 lab results:\")\n",
    "print(top_5_Y123)\n",
    "\n",
    "\n",
    "# Extract the MPINumber of the patient with the most Y123 lab results\n",
    "top_patient = top_5_Y123.iloc[0]['MPINumber']\n",
    "\n",
    "# Filter the dataframe for this patient's Y123 lab results\n",
    "df_top_patient_Y123 = df_Y123[df_Y123['MPINumber'] == top_patient]\n",
    "\n",
    "# Ensure 'Lab Value' column contains only numeric data\n",
    "df_top_patient_Y123['Value'] = pd.to_numeric(df_top_patient_Y123['Value'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in 'Lab Value' column\n",
    "df_top_patient_Y123 = df_top_patient_Y123.dropna(subset=['Value'])\n",
    "\n",
    "\n",
    "# Plot the lab values for the patient with the most Y123 lab results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(df_top_patient_Y123['Value'])\n",
    "plt.xlabel('Lab Value')\n",
    "plt.title(f'Boxplot of Lab Values for Patient {top_patient}')\n",
    "plt.show()\n",
    "```\n",
    "\"\"\"\n",
    "        },         \n",
    "        \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(llm_chat, add_generation_prompt=True, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_template_few_chain(df: pd.DataFrame, query: str, tokenizer):\n",
    "    llm_chat = [\n",
    "                {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "Always think step by step.\n",
    "Your job is to always write python code for the given dataframe `df` using pandas, numpy and matplot library.\n",
    "Never execute the code.\n",
    "            \n",
    "The first twenty rows of the dataframe are:\n",
    "{df.head(20)}\n",
    "            \n",
    "The columns of the dataframe are:\n",
    "{df.columns}\n",
    "\n",
    "Every patient has a unique `MPINumber`.          \n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\"\n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "Count the number of patients.\n",
    "Then, count the number of diagnoses. \n",
    "Then, count the number of patients with a X00 diagnosis.\n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\"\n",
    "```\n",
    "# Number of patients\n",
    "print(len(df['MPINumber'].unique()))\n",
    "``` \n",
    "\n",
    "```\n",
    "# Count diagnoses\n",
    "df_diagnoses = df[df['Finding'] == 'Diagnose']\n",
    "print(len(df_diagnoses))\n",
    "```\n",
    "\n",
    "```\n",
    "# Count X00 patients\n",
    "df_X00 = df[(df['Finding'].str.contains('Diagnose')) & (df['Value'].str.contains('X00'))]['MPINumber'].unique()\n",
    "print(len(df_X00))\n",
    "```            \n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "Plot patients with a Y123 lab result against patients without one in a pie chart. Include percentages and a legend.       \n",
    "\"\"\"            \n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\" \n",
    "```\n",
    "# Filter dataframe for patients with and without 'Y123' lab result\n",
    "df_Y123 = df[(df['Source'].str.contains('Labor')) & (df['Finding'].str.contains('Y123'))]['MPINumber'].unique()\n",
    "df_no_Y123 = df[~df['MPINumber'].isin(df_Y123)]\n",
    "\n",
    "# Count number of patients in each group\n",
    "num_Y123 = len(df_Y123)\n",
    "num_no_Y123 = len(df_no_Y123)\n",
    "\n",
    "# Plot pie chart\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = ['Patients with Y123 lab result', 'Patients without Y123 lab result']\n",
    "sizes = [num_Y123, num_no_Y123]\n",
    "\n",
    "plt.pie(sizes, labels=labels, startangle=90, autopct='%1.1f%%')\n",
    "plt.axis('equal')\n",
    "plt.title('Patients with and without Y123 lab result')\n",
    "plt.legend(title='Patients', loc='upper right')\n",
    "plt.show()\n",
    "``` \n",
    "\"\"\"\n",
    "        },\n",
    "                \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "Which 5 patients had the most Y123 lab result? Plot the values for the patient with the most results in a boxplot.     \n",
    "\"\"\"            \n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\"\n",
    "```\n",
    "# Filter for patients with y123 lab result             \n",
    "df_Y123 = df[(df['Source'].str.contains('Labor')) & (df['Finding'].str.contains('Y123'))]\n",
    "\n",
    "# Group by 'MPINumber' and count the occurrences of 'Y123' lab results\n",
    "df_Y123_counts = df_Y123.groupby('MPINumber').size().reset_index(name='Count')\n",
    "\n",
    "# Sort by count in descending order and select the top 5 patients\n",
    "top_5_Y123 = df_Y123_counts.sort_values(by='Count', ascending=False).head(5)\n",
    "\n",
    "# Display the top 5 patients with the most Y123 lab results\n",
    "print(\"Top 5 patients with the most Y123 lab results:\")\n",
    "print(top_5_Y123)\n",
    "\n",
    "\n",
    "# Extract the MPINumber of the patient with the most Y123 lab results\n",
    "top_patient = top_5_Y123.iloc[0]['MPINumber']\n",
    "\n",
    "# Filter the dataframe for this patient's Y123 lab results\n",
    "df_top_patient_Y123 = df_Y123[df_Y123['MPINumber'] == top_patient]\n",
    "\n",
    "# Ensure 'Lab Value' column contains only numeric data\n",
    "df_top_patient_Y123['Value'] = pd.to_numeric(df_top_patient_Y123['Value'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in 'Lab Value' column\n",
    "df_top_patient_Y123 = df_top_patient_Y123.dropna(subset=['Value'])\n",
    "\n",
    "\n",
    "# Plot the lab values for the patient with the most Y123 lab results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(df_top_patient_Y123['Value'])\n",
    "plt.xlabel('Lab Value')\n",
    "plt.title(f'Boxplot of Lab Values for Patient {top_patient}')\n",
    "plt.show()\n",
    "```\n",
    "\"\"\"\n",
    "        },         \n",
    "        \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(llm_chat, add_generation_prompt=True, tokenize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries - Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPINumber</th>\n",
       "      <th>Source</th>\n",
       "      <th>CollectedDT</th>\n",
       "      <th>Finding</th>\n",
       "      <th>Value</th>\n",
       "      <th>AdditionalInformation</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P-511087658</td>\n",
       "      <td>Stammdaten</td>\n",
       "      <td>2022-07-26 06:55:00</td>\n",
       "      <td>Geburtsdatum</td>\n",
       "      <td>11/1963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P-511087658</td>\n",
       "      <td>Stammdaten</td>\n",
       "      <td>2009-06-30 19:12:00</td>\n",
       "      <td>Geschlecht</td>\n",
       "      <td>weiblich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P-511087658</td>\n",
       "      <td>Diagnosen</td>\n",
       "      <td>2009-07-01 06:15:00</td>\n",
       "      <td>Diagnose</td>\n",
       "      <td>N18.0</td>\n",
       "      <td>Terminale Niereninsuffizienz</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P-511087658</td>\n",
       "      <td>Diagnosen</td>\n",
       "      <td>2009-06-30 19:10:00</td>\n",
       "      <td>Diagnose</td>\n",
       "      <td>D63.8*</td>\n",
       "      <td>Anämie bei sonstigen chronischen, anderenorts ...</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P-511087658</td>\n",
       "      <td>Diagnosen</td>\n",
       "      <td>2009-06-30 19:10:00</td>\n",
       "      <td>Diagnose</td>\n",
       "      <td>E10.60+</td>\n",
       "      <td>Primär insulinabhängiger Diabetes mellitus [Ty...</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33722</th>\n",
       "      <td>P-079860025</td>\n",
       "      <td>Diagnosen</td>\n",
       "      <td>2023-11-24 07:41:00</td>\n",
       "      <td>Diagnose</td>\n",
       "      <td>H26.8</td>\n",
       "      <td>Sonstige näher bezeichnete Kataraktformen</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33723</th>\n",
       "      <td>P-079860025</td>\n",
       "      <td>Diagnosen</td>\n",
       "      <td>2023-11-24 07:41:00</td>\n",
       "      <td>Diagnose</td>\n",
       "      <td>H35.8</td>\n",
       "      <td>Sonstige näher bezeichnete Affektionen der Net...</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33724</th>\n",
       "      <td>P-079860025</td>\n",
       "      <td>Diagnosen</td>\n",
       "      <td>2023-11-24 07:41:00</td>\n",
       "      <td>Diagnose</td>\n",
       "      <td>H36.0*</td>\n",
       "      <td>Retinopathia diabetica</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33725</th>\n",
       "      <td>P-079860025</td>\n",
       "      <td>Diagnosen</td>\n",
       "      <td>2023-11-24 07:41:00</td>\n",
       "      <td>Diagnose</td>\n",
       "      <td>H45.0*</td>\n",
       "      <td>Glaskörperblutung bei anderenorts klassifizier...</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33726</th>\n",
       "      <td>P-079860025</td>\n",
       "      <td>Labor</td>\n",
       "      <td>2023-08-30 13:34:00</td>\n",
       "      <td>GFR-CKDgesamt</td>\n",
       "      <td>7</td>\n",
       "      <td>ml/min</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29330 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MPINumber      Source         CollectedDT        Finding     Value  \\\n",
       "0      P-511087658  Stammdaten 2022-07-26 06:55:00   Geburtsdatum   11/1963   \n",
       "1      P-511087658  Stammdaten 2009-06-30 19:12:00     Geschlecht  weiblich   \n",
       "2      P-511087658   Diagnosen 2009-07-01 06:15:00       Diagnose     N18.0   \n",
       "3      P-511087658   Diagnosen 2009-06-30 19:10:00       Diagnose    D63.8*   \n",
       "4      P-511087658   Diagnosen 2009-06-30 19:10:00       Diagnose   E10.60+   \n",
       "...            ...         ...                 ...            ...       ...   \n",
       "33722  P-079860025   Diagnosen 2023-11-24 07:41:00       Diagnose     H26.8   \n",
       "33723  P-079860025   Diagnosen 2023-11-24 07:41:00       Diagnose     H35.8   \n",
       "33724  P-079860025   Diagnosen 2023-11-24 07:41:00       Diagnose    H36.0*   \n",
       "33725  P-079860025   Diagnosen 2023-11-24 07:41:00       Diagnose    H45.0*   \n",
       "33726  P-079860025       Labor 2023-08-30 13:34:00  GFR-CKDgesamt         7   \n",
       "\n",
       "                                   AdditionalInformation   Age  \n",
       "0                                                    NaN  58.0  \n",
       "1                                                    NaN  45.0  \n",
       "2                           Terminale Niereninsuffizienz  45.0  \n",
       "3      Anämie bei sonstigen chronischen, anderenorts ...  45.0  \n",
       "4      Primär insulinabhängiger Diabetes mellitus [Ty...  45.0  \n",
       "...                                                  ...   ...  \n",
       "33722          Sonstige näher bezeichnete Kataraktformen  59.0  \n",
       "33723  Sonstige näher bezeichnete Affektionen der Net...  59.0  \n",
       "33724                             Retinopathia diabetica  59.0  \n",
       "33725  Glaskörperblutung bei anderenorts klassifizier...  59.0  \n",
       "33726                                             ml/min  59.0  \n",
       "\n",
       "[29330 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your dataframe for testing\n",
    "df = df_P.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backups in case the generated code modifies the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbackup = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfbackup.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start testing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coose your prompting template and your question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Template = query_template_zero\n",
    "\n",
    "Question = Question_H_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Presence_penalty = 0.8\n",
    "Repetition_penalty = 0.8\n",
    "Temperature = 0.1\n",
    "Top_p = 0.1\n",
    "Max_tokens = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = Template(df, Question, tokenizer)\n",
    "llm_outputs = llm.generate(query, SamplingParams\n",
    "                           (presence_penalty=Presence_penalty, \n",
    "                            repetition_penalty=Repetition_penalty, \n",
    "                            temperature=Temperature, \n",
    "                            top_p=Top_p, \n",
    "                            max_tokens=Max_tokens))\n",
    "for i, out in enumerate(llm_outputs):\n",
    "    print('Output:')\n",
    "    print(out.outputs[0].text)\n",
    "    print('#########')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Testing - Space to test generated code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
